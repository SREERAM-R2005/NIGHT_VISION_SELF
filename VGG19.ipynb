{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SREERAM-R2005/NIGHT_VISION_SELF/blob/main/VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66-WNHng-vRQ"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "\n",
        "from torch.utils.data import DataLoader                    #imports\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms                  # This lets us easily download the Fashion MNIST dataset\n",
        "\n",
        "# This ensures that our results are predictable\n",
        "torch.manual_seed(0)     #setting the seed to 0 to get fixed random sequence\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rDgxlnF-vRT"
      },
      "outputs": [],
      "source": [
        "n_epochs = 100\n",
        "input_dim = 32               # found the dimensions from the dataset using print(data.shape)\n",
        "output_classes = 10          # Checked for distinct labels in dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  #setting torch device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y46qkpLENHeU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d618fd71-4af0-4f10-959a-26b7e9648dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 39309381.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                                   # Convert PIL Image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizes the tensor\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True,                       # To download the CIFAR-10 dataset\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,                       # Load CIFAR-10 test dataset\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,          # Define data loaders to load data in batches\n",
        "                                             shuffle=True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64,\n",
        "                                             shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9ycT6X1OwiE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "f7afb8bc-95d5-45cc-bf16-02ca2e214123"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 4\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def imshow(img):                             # Define a function to display an image\n",
        "    img = img / 2 + 0.5                      # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get a random image from the dataset\n",
        "idx = 41451\n",
        "image, label = train_dataset[idx]\n",
        "\n",
        "# Display the image\n",
        "imshow(image)\n",
        "print('Label:', label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr8NWKMS-vRW"
      },
      "outputs": [],
      "source": [
        "class VGG19(nn.Module):\n",
        "    def __init__(self):\n",
        "        nn.Module.__init__(self)\n",
        "        self.convolutions = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fully_connected = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=512, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.7),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.7),\n",
        "            nn.Linear(in_features=4096, out_features=1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.7),\n",
        "            nn.Linear(in_features=1000, out_features=10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.convolutions(inputs)         #  Forward passing the inputs\n",
        "        x = self.fully_connected(x)\n",
        "        return x\n",
        "\n",
        "vgg19 = VGG19()                                      # creating a model after defining the architecture\n",
        "\n",
        "cnn_optimizer = torch.optim.Adam(vgg19.parameters())  # using adam as our optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()                      # defining loss function as cross entropy loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Lenet5(nn.Module):\n",
        "     def __init__(self):\n",
        "         nn.Module.__init__(self)\n",
        "         self.convolutions = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),  # 32, 32, 3 --> 28,28,6\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),  # 28,28,6 --> 14,14,6\n",
        "             nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 14,14,6 --> 10,10,16\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),  # 10,10,16 --> 5,5,16\n",
        "         )\n",
        "\n",
        "         self.fully_connected = nn.Sequential(\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(in_features=5 * 5 * 16, out_features=120),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Linear(in_features=120, out_features=84),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Linear(in_features=84, out_features=10),\n",
        "             nn.Softmax(dim=1),\n",
        "         )\n",
        "\n",
        "     def forward(self, inputs):\n",
        "         x = self.convolutions(inputs)\n",
        "         x = self.fully_connected(x)\n",
        "         return x\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "     def __init__(self):\n",
        "         nn.Module.__init__(self)\n",
        "         self.convolutions = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11,stride=4), # 227, 227, 3 --> 55, 55, 96\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=3, stride=2), # 55, 55, 96 --> 27,27, 96\n",
        "\n",
        "             nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2), # 27, 27, 96 --> 27, 27, 256\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=3, stride=2), # 27, 27, 256 --> 13,13, 256\n",
        "\n",
        "             nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # 13, 13, 256 --> 13, 13, 384\n",
        "             nn.ReLU(inplace=True),\n",
        "\n",
        "             nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3,stride=1, padding=1), # 13, 13, 384 --> 13, 13, 256\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=3, stride=2), # 13, 13, 256 --> 6, 6,256\n",
        "         )\n",
        "         self.fully_connected = nn.Sequential(\n",
        "             nn.Flatten(),\n",
        "             nn.Dropout(p=0.2),\n",
        "             nn.Linear(in_features=6 * 6 * 256, out_features=4096),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Dropout(p=0.2),\n",
        "             nn.Linear(in_features=4096, out_features=4096),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Linear(in_features=4096, out_features=10),\n",
        "             nn.Softmax(dim=1),\n",
        "         )\n",
        "\n",
        "     def forward(self, inputs):\n",
        "         x = self.convolutions(inputs)\n",
        "         x = self.fully_connected(x)\n",
        "         return x\n",
        "\n",
        "le = Lenet5()\n",
        "alex = AlexNet()"
      ],
      "metadata": {
        "id": "8KaIRH_p0koE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoP8Yi5S-vRW"
      },
      "outputs": [],
      "source": [
        "# Defining one epoch of training\n",
        "def train(model, train_loader, optimizer=cnn_optimizer, loss=loss_fn):\n",
        "    # We train the appropriate model with the input data and the appropriate optimizer\n",
        "    # ps is how often we print the accuracy\n",
        "\n",
        "    model=model.to(device)\n",
        "\n",
        "\n",
        "    train_iter = iter(train_loader)\n",
        "    model.train()\n",
        "    # Puts model in train mode\n",
        "\n",
        "    acc_hist = []\n",
        "    for i, (data, targets) in enumerate(train_iter):\n",
        "        # i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\n",
        "        # This repeats for all mini batches\n",
        "\n",
        "        data=data.to(device)\n",
        "        targets=targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Ensures gradients stored in optimizer are reset before each backward pass\n",
        "\n",
        "        outputs = model.forward(data) # Forward pass\n",
        "\n",
        "        loss_val = loss(outputs, targets) # Loss computation\n",
        "        loss_val.backward() # Backward pass\n",
        "        optimizer.step() # Backward pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV6xOC57-vRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "b483e5c7-a728-4673-c49f-fca6b059fa70"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-db1e1b48c784>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m            \u001b[0;31m# passing entire dataset once ie 1 epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-e5e814de1307>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, loss)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i in range(n_epochs):            # passing entire dataset once ie 1 epoch\n",
        "  train(vgg19, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLetV0qZ-vRY"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, test):\n",
        "    # Evaluate a model given a test loader\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        count = 0\n",
        "        correct = 0\n",
        "        for data, targets in iter(test):\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model.forward(data)\n",
        "            predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
        "            count += len(targets) # Total length of datasets\n",
        "            correct += (predicted == targets.to(device)).sum().item()\n",
        "            # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
        "        print((predicted == targets).sum().item())\n",
        "        accuracy = correct/count\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5JVyPvB-vRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a99b2a-945e-4ab3-f524-64d445ee18bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "\n",
            "    Accuracy on test dataset for CNN is  10.00000%.\n",
            "    Accuracy on train datset for CNN is  10.00000%.\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "cnn_acc_test = (accuracy(vgg19, test_loader))\n",
        "cnn_acc_train = (accuracy(vgg19, train_loader))\n",
        "print(\n",
        "    f'''\n",
        "    Accuracy on test dataset for CNN is {cnn_acc_test*100: .5f}%.\n",
        "    Accuracy on train datset for CNN is {cnn_acc_train*100: .5f}%.\n",
        "    '''\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWaEllMMBkkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_OTL9XY72tyd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}