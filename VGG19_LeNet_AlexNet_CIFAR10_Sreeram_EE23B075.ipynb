{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SREERAM-R2005/NIGHT_VISION_SELF/blob/main/CNN_implementation_CIFAR10_Sreeram_EE23B075.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66-WNHng-vRQ"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader                    #imports\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms                  # This lets us easily download the Fashion MNIST dataset\n",
        "\n",
        "# This emsures that our results are predictable\n",
        "torch.manual_seed(0)     #setting the seed to 0 to get fixed random sequence\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rDgxlnF-vRT"
      },
      "outputs": [],
      "source": [
        "n_epochs = 1\n",
        "input_dim = 32               # found the dimensions from the dataset using print(data.shape)\n",
        "output_classes = 10          # Checked for distinct labels in dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  #setting torch device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y46qkpLENHeU"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),                                   # Convert PIL Image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizes the tensor\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True,                       # To download the CIFAR10 dataset\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False,                       # Load CIFAR-10 test dataset\n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,          # Define data loaders to load data in batches\n",
        "                                           shuffle=True, num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64,\n",
        "                                          shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9ycT6X1OwiE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def imshow(img):                             # Define a function to display an image\n",
        "    img = img / 2 + 0.5                      # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get a random image from the dataset\n",
        "idx = 41451\n",
        "image, label = train_dataset[idx]\n",
        "\n",
        "# Display the image\n",
        "imshow(image)\n",
        "print('Label:', label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr8NWKMS-vRW"
      },
      "outputs": [],
      "source": [
        "class VGG19(nn.Module):\n",
        "    def __init__(self):\n",
        "        nn.Module.__init__(self)\n",
        "        self.convolutions = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.fully_connected = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=512, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.7),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.7),\n",
        "            nn.Linear(in_features=4096, out_features=1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.7),\n",
        "            nn.Linear(in_features=1000, out_features=10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.convolutions(inputs)         #  Forward passing the inputs\n",
        "        x = self.fully_connected(x)\n",
        "        return x\n",
        "\n",
        "vgg19 = VGG19()                                      # creating a model after defining the architecture\n",
        "\n",
        "cnn_optimizer = torch.optim.Adam(vgg19.parameters())  # using adam as our optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()                      # defining loss function as cross entropy loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Lenet5(nn.Module):\n",
        "     def __init__(self):\n",
        "         nn.Module.__init__(self)\n",
        "         self.convolutions = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),  # 32, 32, 3 --> 28,28,6\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),  # 28,28,6 --> 14,14,6\n",
        "             nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),  # 14,14,6 --> 10,10,16\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=2, stride=2),  # 10,10,16 --> 5,5,16\n",
        "         )\n",
        "\n",
        "         self.fully_connected = nn.Sequential(\n",
        "             nn.Flatten(),\n",
        "             nn.Linear(in_features=5 * 5 * 16, out_features=120),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Linear(in_features=120, out_features=84),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Linear(in_features=84, out_features=10),\n",
        "             nn.Softmax(dim=1),\n",
        "         )\n",
        "\n",
        "     def forward(self, inputs):\n",
        "         x = self.convolutions(inputs)\n",
        "         x = self.fully_connected(x)\n",
        "         return x\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "     def __init__(self):\n",
        "         nn.Module.__init__(self)\n",
        "         self.convolutions = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11,stride=4), # 227, 227, 3 --> 55, 55, 96\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=3, stride=2), # 55, 55, 96 --> 27,27, 96\n",
        "\n",
        "             nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2), # 27, 27, 96 --> 27, 27, 256\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=3, stride=2), # 27, 27, 256 --> 13,13, 256\n",
        "\n",
        "             nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # 13, 13, 256 --> 13, 13, 384\n",
        "             nn.ReLU(inplace=True),\n",
        "\n",
        "             nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3,stride=1, padding=1), # 13, 13, 384 --> 13, 13, 256\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.MaxPool2d(kernel_size=3, stride=2), # 13, 13, 256 --> 6, 6,256\n",
        "         )\n",
        "         self.fully_connected = nn.Sequential(\n",
        "             nn.Flatten(),\n",
        "             nn.Dropout(p=0.2),\n",
        "             nn.Linear(in_features=6 * 6 * 256, out_features=4096),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Dropout(p=0.2),\n",
        "             nn.Linear(in_features=4096, out_features=4096),\n",
        "             nn.ReLU(inplace=True),\n",
        "             nn.Linear(in_features=4096, out_features=10),\n",
        "             nn.Softmax(dim=1),\n",
        "         )\n",
        "\n",
        "     def forward(self, inputs):\n",
        "         x = self.convolutions(inputs)\n",
        "         x = self.fully_connected(x)\n",
        "         return x\n",
        "\n",
        "le = Lenet5()\n",
        "alex = AlexNet()"
      ],
      "metadata": {
        "id": "8KaIRH_p0koE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoP8Yi5S-vRW"
      },
      "outputs": [],
      "source": [
        "# Defining one epoch of training\n",
        "def train(model, train_loader, optimizer=cnn_optimizer, loss=loss_fn):\n",
        "    # We train the appropriate model with the input data and the appropriate optimizer\n",
        "    # ps is how often we print the accuracy\n",
        "\n",
        "    model=model.to(device)\n",
        "\n",
        "\n",
        "    train_iter = iter(train_loader)\n",
        "    model.train()\n",
        "    # Puts model in train mode\n",
        "\n",
        "    acc_hist = []\n",
        "    for i, (data, targets) in enumerate(train_iter):\n",
        "        # i is iteration, data = 1 mini batch of images, targets = 1 mini batch target values\n",
        "        # This repeats for all mini batches\n",
        "\n",
        "        data=data.to(device)\n",
        "        targets=targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Ensures gradients stored in optimizer are reset before each backward pass\n",
        "\n",
        "        outputs = model.forward(data) # Forward pass\n",
        "\n",
        "        loss_val = loss(outputs, targets) # Loss computation\n",
        "        loss_val.backward() # Backward pass\n",
        "        optimizer.step() # Backward pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV6xOC57-vRX"
      },
      "outputs": [],
      "source": [
        "for i in range(n_epochs):            # passing entire dataset once ie 1 epoch\n",
        "  train(vgg19, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLetV0qZ-vRY"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, test):\n",
        "    # Evaluate a model given a test loader\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        count = 0\n",
        "        correct = 0\n",
        "        for data, targets in iter(test):\n",
        "            outputs = model.forward(data)\n",
        "            predicted = outputs.max(1)[1] # Maximum output is predicted class\n",
        "            count += len(targets) # Total length of datasetS\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            # This gives a tensor of True and False values and adds no. of True values to correct each iteration\n",
        "        # print((predicted == targets).sum().item())\n",
        "        accuracy = correct/count\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5JVyPvB-vRZ"
      },
      "outputs": [],
      "source": [
        "cnn_acc_test = (accuracy(vgg19, test_loader))\n",
        "cnn_acc_train = (accuracy(vgg19, train_loader))\n",
        "print(\n",
        "    f'''\n",
        "    Accuracy on test dataset for CNN is {cnn_acc_test*100: .5f}%.\n",
        "    Accuracy on train datset for CNN is {cnn_acc_train*100: .5f}%.\n",
        "    '''\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_OTL9XY72tyd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
